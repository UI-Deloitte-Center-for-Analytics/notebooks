{"cells":[{"cell_type":"markdown","metadata":{},"source":["# üî¨Aggregations and Intro to Merges"]},{"cell_type":"markdown","metadata":{},"source":["‚ñ∂Ô∏è Run the code cell below to import `unittest`, a module used for **üß≠ Check Your Work** sections."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import unittest\n","tc = unittest.TestCase()"]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","### üéØ Import `numpy` and `pandas`\n","\n","#### üëá Tasks\n","\n","- ‚úîÔ∏è Import the following Python packages.\n","    1. `pandas`: Use alias `pd`.\n","    2. `numpy`: Use alias `np`."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### BEGIN SOLUTION\n","\n","\n","### END SOLUTION"]},{"cell_type":"markdown","metadata":{},"source":["#### üß≠ Check your work\n","\n","- Once you're done, run the code cell below to test correctness.\n","- ‚úîÔ∏è If the code cell runs without an error, you're good to move on.\n","- ‚ùå If the code cell throws an error, go back and fix incorrect parts."]},{"cell_type":"code","execution_count":null,"metadata":{"nbgrader":{"grade":true,"grade_id":"pre-challenge","locked":true,"points":"1","solution":false}},"outputs":[],"source":["# Result Check\n","tc.assertTrue('pd' in globals(), 'Check whether you have correctly import Pandas with an alias.')\n","tc.assertTrue('np' in globals(), 'Check whether you have correctly import NumPy with an alias.')\n","\n","# check whether pd and np are valid aliases to pandas and numpy\n","tc.assertTrue(hasattr(pd, 'DataFrame'))\n","tc.assertTrue(hasattr(np, 'ufunc'))"]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","## üî¨ Grouping and Aggregating Data with Pandas\n","\n","üëâ A very common task in working with data is to *summarize* your data by one or more columns. As an example, you may want to find out the average salary of employees by department. Pandas allows you to use a [*split-apply-combine*](https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html) pattern to perform those types of tasks."]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","### üìå Create employees data\n","\n","‚ñ∂Ô∏è Run the code cell below to create a new `DataFrame` named `df`."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = pd.DataFrame({\n","    'name': ['Mary', 'Roy', 'John', 'Joe', 'Paul', 'Erin'],\n","    'dept': ['Finance', 'Purchase', 'Finance', 'Purchase', 'Finance', 'Purchase'],\n","    'salary': [240000, 160000, 250000, 170000, 260000, 180000]}\n",")\n","\n","df"]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","### üìå Creating a `DataFrameGroupBy` object\n","\n","‚ñ∂Ô∏è Run `df.groupby('dept')` below."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### BEGIN SOLUTION\n","\n","### END SOLUTION"]},{"cell_type":"markdown","metadata":{},"source":["#### Notes\n","\n","- Internally, Pandas will create one group per department when you run `.groupby('dept')`.\n","- However, you will be able to see the groups until we apply aggregation function(s) to each group.\n","- The strange-looking output (in the form of `<pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000012345678910>`) tells us that the result is a `DataFrameGroupBy` object.\n","- The diagram below describes what Pandas is doing behind the scene.\n","\n","![groupby object](https://github.com/bdi475/images/blob/main/pandas/df-groupby-object-01.png?raw=true)"]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","### üìå Aggregating a `DataFrameGroupBy` object\n","\n","‚ñ∂Ô∏è Run `df.groupby('dept').agg({'salary': 'mean'})` below."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### BEGIN SOLUTION\n","\n","### END SOLUTION"]},{"cell_type":"markdown","metadata":{},"source":["üëâ Your resulting `DataFrame` now displays average salary by `dept`.\n","\n","#### Columns used as \"pivots\"\n","\n","```python\n","df_salary_by_dept = df.groupby('dept').agg({'salary': 'mean'})\n","\n","display(df_salary_by_dept)\n","print(df_salary_by_dept.columns)\n","```\n","\n","‚ñ∂Ô∏è Copy the provided code above to the code cell below and run it."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### BEGIN SOLUTION\n","\n","\n","\n","\n","### END SOLUTION"]},{"cell_type":"markdown","metadata":{},"source":["üëâ There is only one column shown when you print out `df_salary_by_dept.columns`! üôÄ\n","\n","This is because the column(s) you use to create groups are used as **index** by default.\n","\n","![groupby agg result](https://github.com/bdi475/images/blob/main/pandas/df-groupby-agg-as-index-true-01.png?raw=true)"]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","### üìå Aggregating a `DataFrameGroupBy` object with optional `index=False`\n","\n","```python\n","df_salary_by_dept2 = df.groupby('dept', as_index=False).agg({'salary': 'mean'})\n","\n","display(df_salary_by_dept2)\n","print(df_salary_by_dept2.columns)\n","```\n","\n","‚ñ∂Ô∏è Copy the provided code to the code cell below and run it."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### BEGIN SOLUTION\n","\n","\n","\n","\n","### END SOLUTION"]},{"cell_type":"markdown","metadata":{},"source":["üëâ Now, printing out the columns show both `dept` and `salary`. Supplying `as_index=False` to `groupby()` keeps the columns you use as the \"pivot\" as regular columns.\n","\n","![groupby agg result](https://github.com/bdi475/images/blob/main/pandas/df-groupby-agg-as-index-false-01.png?raw=true)"]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","### üìå Creating multiple aggregation measures\n","\n","```python\n","df_salary_by_dept3 = df.groupby('dept', as_index=False).agg({'salary': ['min', 'max', 'mean', 'sum', 'count', 'std']})\n","\n","display(df_salary_by_dept3)\n","print(df_salary_by_dept3.columns)\n","```\n","\n","‚ñ∂Ô∏è Copy the provided code to the code cell below and run it."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### BEGIN SOLUTION\n","\n","\n","\n","\n","### END SOLUTION"]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","### üìå Flattening multi-level index columns\n","\n","When you apply two or more aggregation functions to a column, your DataFrame creates a hierarchically structured columns. It is often easier to work with a DataFrame if you have a flat-level columns. You can manually assign the column names after `.agg()` in these cases to *flatten* the columns.\n","\n","```python\n","df_salary_by_dept4 = df.groupby('dept', as_index=False).agg({'salary': ['min', 'max', 'mean', 'sum', 'count', 'std']})\n","\n","display(df_salary_by_dept4)\n","print('Columns before (multi-level, not flat):')\n","print(df_salary_by_dept4.columns)\n","\n","# manually assign column names\n","df_salary_by_dept4.columns = ['dept', 'min_salary', 'max_salary', 'mean_salary', 'total_salary', 'num_employees', 'std_dev']\n","\n","display(df_salary_by_dept4)\n","print('Columns after (flat-level):')\n","print(df_salary_by_dept4.columns)\n","```\n","\n","‚ñ∂Ô∏è Copy the provided code to the code cell below and run it."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_salary_by_dept4 = df.groupby('dept', as_index=False).agg({'salary': ['min', 'max', 'mean', 'sum', 'count', 'std']})\n","\n","display(df_salary_by_dept4)\n","print('Columns before (multi-level, not flat):')\n","print(df_salary_by_dept4.columns)\n","\n","# manually assign column names\n","df_salary_by_dept4.columns = ['dept', 'min_salary', 'max_salary', 'mean_salary', 'total_salary', 'num_employees', 'std_dev']\n","\n","display(df_salary_by_dept4)\n","print('Columns after (flat-level):')\n","print(df_salary_by_dept4.columns)"]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","## üìû Exercises Using Bank Marketing Calls Data\n","\n","You'll work with a dataset related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls.\n","\n","Citation: [Moro et al., 2014] S. Moro, P. Cortez and P. Rita. A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems, Elsevier, 62:22-31, June 2014\n","\n","UCI Machine Learning Repository Dataset Link: [https://archive.ics.uci.edu/ml/datasets/bank+marketing](https://archive.ics.uci.edu/ml/datasets/bank+marketing) - The dataset has been modified to fit this mini case -study.\n","\n","\n","| Column Name     | Type        | Description                                                                                                                                                     |\n","|-----------------|-------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------|\n","| `age`           | Numeric     | Age                                                                                                                                                             |\n","| `job`           | Categorical | admin.', 'blue-collar',   'entrepreneur', 'housemaid', 'management', 'retired', 'self-employed',   'services', 'student', 'technician', 'unemployed', 'unknown' |\n","| `marital`       | Categorical | single', 'married', 'divorced', 'unknown'                                                                                                                       |\n","| `education`     | Categorical | basic.4y', 'basic.6y', 'basic.9y', 'high.school', 'illiterate',   'professional.course', 'university.degree', 'unknown'                                         |\n","| `contact_type`  | Categorical | cellular', 'telephone'                                                                                                                                          |\n","| `num_contacts`  | Numeric     | Number of contacts performed during this campaign for this client                                                                                               |\n","| `prev_outcome`  | Categorical | Outcome of the previous marketing campaign - 'failure', 'nonexistent',   'success'                                                                              |\n","| `place_deposit` | Numeric     | Did the client subscribe to a term deposit? This column indicates whether the campaign was successful (1) or not (0) for each client.                                        |\n","\n","---\n","\n","\n","Your goal is to analyze the dataset to discover relationships between personal factors and marketing campaign result of each individual.\n","\n","**`place_deposit`** column indicates whether a marketing campaign was successful.\n","\n","- ‚úÖ If `1`, the individual has placed a deposit within the bank. This is considered a **successful campaign**.\n","- üö´ If `0`, the individual has not placed a deposit within the bank. This is considered an **unsuccessful campaign**."]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","### üìå Load data"]},{"cell_type":"markdown","metadata":{},"source":["‚ñ∂Ô∏è Run the code cell below to create a new `DataFrame` named `df_m`."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_m = pd.read_csv('https://github.com/UI-Deloitte-Center-for-Analytics/datasets/blob/main/bank-direct-marketing.csv?raw=true')\n","df_m_backup = df_m.copy()\n","df_m"]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","### üéØ Challenge 1: Marketing success rate by marital status\n","\n","#### üëá Tasks\n","\n","- ‚úîÔ∏è Using `df_m`, create an aggregated table named `df_by_marital` that lists the success rate (average of the `place_deposit` column) by marital status.\n","- ‚úîÔ∏è Use the `as_index=False` option.\n","- ‚úîÔ∏è The aggregated DataFrame should have two columns - \"marital\" and \"success_rate\".\n","- ‚úîÔ∏è `df_by_marital` should only have the following two columns in the same order.\n","    - `marital`: Marital status (e.g., single, divorced, married, unknown)\n","    - `success_rate`: Average success rate (between 0-1)\n","- ‚úîÔ∏è Both columns should not be used as an index column.\n","    - Printing `df_by_marital.columns.to_list()` should print out `['marital', 'success_rate']`.\n","- ‚úîÔ∏è Sort `df_by_marital` by `success_rate` in descending order *in-place*.\n","\n","#### üîë Expected Output\n","\n","|    | marital   |   success_rate |\n","|---:|:----------|---------------:|\n","|  3 | unknown   |       0.15     |\n","|  2 | single    |       0.140041 |\n","|  0 | divorced  |       0.103209 |\n","|  1 | married   |       0.101573 |"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### BEGIN SOLUTION\n","\n","\n","\n","### END SOLUTION\n","\n","df_by_marital"]},{"cell_type":"markdown","metadata":{},"source":["#### üß≠ Check Your Work\n","\n","- Once you're done, run the code cell below to test correctness.\n","- ‚úîÔ∏è If the code cell runs without an error, you're good to move on.\n","- ‚ùå If the code cell throws an error, go back and fix incorrect parts."]},{"cell_type":"code","execution_count":null,"metadata":{"nbgrader":{"grade":true,"grade_id":"challenge-01","locked":true,"points":"1","solution":false}},"outputs":[],"source":["df_check = df_m_backup.groupby('marital', as_index=bool(0)).agg({'place_deposit': np.mean}) \\\n","    .rename(columns={'_'.join(['place', 'deposit']): 'success_rate'}) \\\n","    .sort_values('success_rate').iloc[::-1]\n","df_check = df_check[['success_rate', 'marital'][::-1]].copy()\n","\n","# Check result\n","pd.testing.assert_frame_equal(df_by_marital.reset_index(drop=True),\n","                              df_check.reset_index(drop=True))"]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","### üë©üèº‚Äçüíª Interpreting the output\n","\n","Based on the ouptut above, are single people more likely to sign up for a new account compared to divorced or married people?"]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","### üéØ Challenge 2: Marketing success rate by job\n","\n","#### üëá Tasks\n","\n","- ‚úîÔ∏è Using `df_m`, create an aggregated table named `df_by_job` to that lists the average success rate in direct marketing campaigns by job.\n","- ‚úîÔ∏è Use the `as_index=False` option.\n","- ‚úîÔ∏è `df_by_job` should only have the following two columns in the same order.\n","    - `job`: Job (e.g., student, technician, housemaid, etc)\n","    - `success_rate`: Average success rate (between 0-1)\n","- ‚úîÔ∏è Both columns should not be used as an index column.\n","    - Printing `df_by_job.columns.to_list()` should print out `['job', 'success_rate']`.\n","- ‚úîÔ∏è Sort `df_by_job` by `success_rate` in descending order.\n","\n","#### üîë Expected Output\n","\n","|    | job           |   success_rate |\n","|---:|:--------------|---------------:|\n","|  8 | student       |      0.314286  |\n","|  5 | retired       |      0.252326  |\n","| 10 | unemployed    |      0.142012  |\n","|  0 | admin.        |      0.129726  |\n","|  4 | management    |      0.112175  |\n","| 11 | unknown       |      0.112121  |\n","|  9 | technician    |      0.10826   |\n","|  6 | self-employed |      0.104856  |\n","|  3 | housemaid     |      0.1       |\n","|  2 | entrepreneur  |      0.0851648 |\n","|  7 | services      |      0.0813807 |\n","|  1 | blue-collar   |      0.0689432 |"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### BEGIN SOLUTION\n","\n","\n","\n","### END SOLUTION\n","\n","df_by_job"]},{"cell_type":"markdown","metadata":{},"source":["#### üß≠ Check Your Work\n","\n","- Once you're done, run the code cell below to test correctness.\n","- ‚úîÔ∏è If the code cell runs without an error, you're good to move on.\n","- ‚ùå If the code cell throws an error, go back and fix incorrect parts."]},{"cell_type":"code","execution_count":null,"metadata":{"nbgrader":{"grade":true,"grade_id":"challenge-02","locked":true,"points":"1","solution":false}},"outputs":[],"source":["df_check = df_m_backup.groupby('job').agg({'place_deposit': np.mean}).reset_index() \\\n","    .rename(columns={'_'.join(['place', 'deposit']): 'success_rate'}) \\\n","    .sort_values('success_rate').iloc[::-1]\n","df_check = df_check[['success_rate', 'job'][::-1]].copy()\n","\n","pd.testing.assert_frame_equal(df_by_job.reset_index(drop=True),\n","                              df_check.reset_index(drop=True))"]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","### üïµüèæ‚Äç‚ôÄÔ∏è Interpreting the output\n","\n","Based on the ouptut above, which occupations are most attractive target demographic from the bank's perspective?"]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","### üéØ Challenge 3: Marketing success rate by contact type with count\n","\n","#### üëá Tasks\n","\n","- ‚úîÔ∏è Using `df_m`, create an aggregated table named `df_by_contact_type` that lists the number of campaigns and the average success rate by contact type.\n","- ‚úîÔ∏è Use the `as_index=False` option.\n","- ‚úîÔ∏è `df_by_contact_type` should only have the following three columns in the same order.\n","    - `contact_type`: Contact method (e.g., cellular, telephone)\n","    - `count`: Number of potential customers that were contacted using the corresponding contact type\n","    - `success_rate`: Average success rate (between 0-1)\n","- ‚úîÔ∏è All three columns should not be used as an index column.\n","    - Printing `df_by_contact_type.columns.to_list()` should print out `['contact_type', 'count', 'success_rate']`.\n","- ‚úîÔ∏è Sort `df_by_contact_type` by `success_rate` in descending order.\n","\n","#### üîë Expected Output\n","\n","|    | contact_type   |   count |   success_rate |\n","|---:|:---------------|--------:|---------------:|\n","|  0 | cellular       |   26144 |      0.147376  |\n","|  1 | telephone      |   15044 |      0.0523132 |"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### BEGIN SOLUTION\n","\n","\n","\n","\n","\n","\n","\n","\n","### END SOLUTION\n","df_by_contact_type"]},{"cell_type":"markdown","metadata":{},"source":["#### üß≠ Check Your Work\n","\n","- Once you're done, run the code cell below to test correctness.\n","- ‚úîÔ∏è If the code cell runs without an error, you're good to move on.\n","- ‚ùå If the code cell throws an error, go back and fix incorrect parts."]},{"cell_type":"code","execution_count":null,"metadata":{"nbgrader":{"grade":true,"grade_id":"challenge-03","locked":true,"points":"1","solution":false}},"outputs":[],"source":["df_check = df_m_backup.groupby('_'.join(['contact', 'type'])).agg({'place_deposit': ['count', np.mean]}).reset_index()\n","df_check.columns = ['SUCCESS_RATE'.lower(), 'COUNT'.lower(), 'CONTACT_TYPE'.lower()][::-1]\n","df_check = df_check \\\n","    .sort_values('success_rate').iloc[::-1]\n","\n","pd.testing.assert_frame_equal(df_by_contact_type.reset_index(drop=True),\n","                              df_check.reset_index(drop=True))"]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","### üïµüèΩ Interpreting the output\n","\n","Based on the ouptut above, which method of contact (cellular or telephone) has a higher success rate?"]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","### üìå Grouping by multiple columns\n","\n","You can run a `groupby()` with two or more columns by supplying a `list` of columns to the `groupby()` function.\n","\n","```python\n","# example\n","df.groupby(['column1', 'column2'], as_index=False).agg({ 'column3': ... })\n","```"]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","### üéØ Challenge 4: Marketing success rate by marital status and contact type\n","\n","#### üëá Tasks\n","\n","- ‚úîÔ∏è Using `df_m`, create an aggregated table named `df_by_type_and_marital` that lists the average success rate in direct marketing campaigns by marital status and contact type.\n","- ‚úîÔ∏è Use the `as_index=False` option.\n","- ‚úîÔ∏è `df_by_type_and_marital` should only have the following three columns in the same order.\n","    - `marital`: Marital status (e.g., single, divorced, married, unknown)\n","    - `contact_type`: Contact method (e.g., cellular, telephone)\n","    - `success_rate`: Average success rate (between 0-1)\n","- ‚úîÔ∏è All three columns should not be used as an index column.\n","    - Printing `df_by_type_and_marital.columns.to_list()` should print out `['marital', 'contact_type', 'success_rate']`.\n","- ‚úîÔ∏è Sort `df_by_type_and_marital` by `success_rate` in descending order.\n","\n","#### üîë Expected Output\n","\n","|    | marital   | contact_type   |   success_rate |\n","|---:|:----------|:---------------|---------------:|\n","|  6 | unknown   | cellular       |      0.207547  |\n","|  4 | single    | cellular       |      0.173875  |\n","|  0 | divorced  | cellular       |      0.13652   |\n","|  2 | married   | cellular       |      0.135341  |\n","|  5 | single    | telephone      |      0.0648844 |\n","|  3 | married   | telephone      |      0.0487554 |\n","|  1 | divorced  | telephone      |      0.0463615 |\n","|  7 | unknown   | telephone      |      0.037037  |"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### BEGIN SOLUTION\n","\n","\n","\n","\n","\n","### END SOLUTION\n","\n","df_by_type_and_marital"]},{"cell_type":"markdown","metadata":{},"source":["#### üß≠ Check Your Work\n","\n","- Once you're done, run the code cell below to test correctness.\n","- ‚úîÔ∏è If the code cell runs without an error, you're good to move on.\n","- ‚ùå If the code cell throws an error, go back and fix incorrect parts."]},{"cell_type":"code","execution_count":null,"metadata":{"nbgrader":{"grade":true,"grade_id":"challenge-04","locked":true,"points":"1","solution":false}},"outputs":[],"source":["df_check = df_m_backup.groupby(['MARITAL'.lower(), '_'.join(['contact', 'type'])]) \\\n","    .agg({'place_deposit': np.mean}).reset_index()\n","df_check.rename(columns={'place_deposit': '_'.join(['SUCCESS', 'RATE']).lower()}, inplace=bool(1))\n","df_check = df_check \\\n","    .sort_values('success_rate').iloc[::-1]\n","\n","pd.testing.assert_frame_equal(df_by_type_and_marital.reset_index(drop=True),\n","                              df_check.reset_index(drop=True))"]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","## üß≤ Merging two DataFrames (Joins)\n","\n","Another common operation with tables is to merge two or more tables into one larger table.\n","\n","To demonstrate how merging works, we'll work a record of transactions from a small food stand selling only two items - sweetcorns üåΩ and beers üç∫. The tables associated with the food stand's transactions are shown below.\n","\n","### Products (`df_products`)\n","\n","| product_id | product_name | price |\n","|---|---|---|\n","| SC | Sweetcorn | 3.0 |\n","| CB | Beer | 5.0 |\n","\n","### Transactions (`df_transactions`)\n","\n","| transaction_id | product_id |\n","|---|---|\n","| 1 | SC |\n","| 2 | SC |\n","| 3 | CB |\n","| 4 | SC |\n","| 5 | SC |\n","| 6 | SC |\n","| 7 | CB |\n","| 8 | SC |\n","| 9 | CB |\n","| 10 | SC |\n","\n","‚ñ∂Ô∏è Run the code below to create the two tables as DataFrames."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# DO NOT CHANGE THE CODE BELOW\n","df_products = pd.DataFrame({\n","    'product_id': ['SC', 'CB'],\n","    'product_name': ['Sweetcorn', 'Beer'],\n","    'price': [3.0, 5.0]\n","})\n","\n","df_transactions = pd.DataFrame({\n","    'transaction_id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n","    'product_id': ['SC', 'SC', 'CB', 'SC', 'SC', 'SC', 'CB', 'SC', 'CB', 'SC']\n","})\n","\n","df_products_backup = df_products.copy()\n","df_transactions_backup = df_transactions.copy()\n","\n","display(df_products)\n","display(df_transactions)"]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","### üéØ Challenge 5: Merge products into transactions\n","\n","#### üëá Tasks\n","\n","- ‚úîÔ∏è Using `df_products` and `df_transactions`, create a merged table as shown below.\n","- ‚úîÔ∏è Use a left merge.\n","- ‚úîÔ∏è Name the merged DataFrame `df_merged`.\n","\n","#### üöÄ Hints\n","\n","The code below merges `right_dataframe` into `left_dataframe` using `shared_key_column`. The resulting type of the merge is a left-merge.\n","\n","```python\n","merged_dataframe = pd.merge(\n","    left=left_dataframe,\n","    right=right_dataframe,\n","    on='shared_key_column',\n","    how='left'\n",")\n","```\n","\n","#### üß≠ Expected Output of `df_merged`\n","\n","|  | transaction_id | product_id | product_name | price |\n","|---|---|---|---|---|\n","| 0 | 1 | SC | Sweetcorn | 3.0 |\n","| 1 | 2 | SC | Sweetcorn | 3.0 |\n","| 2 | 3 | CB | Beer | 5.0 |\n","| 3 | 4 | SC | Sweetcorn | 3.0 |\n","| 4 | 5 | SC | Sweetcorn | 3.0 |\n","| 5 | 6 | SC | Sweetcorn | 3.0 |\n","| 6 | 7 | CB | Beer | 5.0 |\n","| 7 | 8 | SC | Sweetcorn | 3.0 |\n","| 8 | 9 | CB | Beer | 5.0 |\n","| 9 | 10 | SC | Sweetcorn | 3.0 |"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### BEGIN SOLUTION\n","\n","\n","\n","\n","\n","\n","### END SOLUTION\n","\n","display(df_merged)"]},{"cell_type":"markdown","metadata":{},"source":["#### üß≠ Check Your Work\n","\n","- Once you're done, run the code cell below to test correctness.\n","- ‚úîÔ∏è If the code cell runs without an error, you're good to move on.\n","- ‚ùå If the code cell throws an error, go back and fix incorrect parts."]},{"cell_type":"code","execution_count":null,"metadata":{"nbgrader":{"grade":true,"grade_id":"challenge-05","locked":true,"points":"1","solution":false}},"outputs":[],"source":["df_merged_SOL = df_transactions_backup.merge(\n","    df_products_backup,\n","    on= '_'.join(['product', 'id']),\n","    how='inner'\n",").sort_values('_'.join(['transaction', 'id']))\n","\n","pd.testing.assert_frame_equal(df_merged.reset_index(drop=True),\n","                              df_merged_SOL.reset_index(drop=True))"]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","### üéØ Challenge 6: Total sales by product\n","\n","#### üëá Tasks\n","\n","- ‚úîÔ∏è Using `df_merged` from the previous exercise, find the total sales by product.\n","- ‚úîÔ∏è Store the grouped result (a DataFrame) to `df_sales_by_product`.\n","- ‚úîÔ∏è Use the `groupby()` method on the `product_id` column.\n","- ‚úîÔ∏è `df_sales_by_product` should contain flat-level columns.\n","    - Printing `df_sales_by_product.columns.to_list()` should print out `['product_id', 'price']`.\n","\n","#### üß≠ Expected Output of `df_sales_by_product`\n","\n","|  | product_id | price |\n","|---|---|---|\n","| 0 | CB | 15.0 |\n","| 1 | SC | 21.0 |"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### BEGIN SOLUTION\n","\n","### END SOLUTION\n","\n","display(df_sales_by_product)"]},{"cell_type":"markdown","metadata":{},"source":["#### üß≠ Check Your Work\n","\n","- Once you're done, run the code cell below to test correctness.\n","- ‚úîÔ∏è If the code cell runs without an error, you're good to move on.\n","- ‚ùå If the code cell throws an error, go back and fix incorrect parts."]},{"cell_type":"code","execution_count":null,"metadata":{"nbgrader":{"grade":true,"grade_id":"challenge-06","locked":true,"points":"1","solution":false}},"outputs":[],"source":["df_merged_SOL = df_transactions_backup.merge(\n","    df_products_backup,\n","    on='product_id',\n","    how='left'\n",")\n","df_sales_by_product_SOL = df_merged_SOL.groupby('PRODUCT_ID'.lower()).agg({'price': np.sum}).reset_index()\n","\n","pd.testing.assert_frame_equal(df_sales_by_product, df_sales_by_product_SOL)"]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","### üéØ Challenge 7: Total sales by product\n","\n","#### üëá Tasks\n","\n","- ‚úîÔ∏è Using `df_merged` from the previous exercise, find the total sales by product.\n","- ‚úîÔ∏è Store the grouped result (a DataFrame) to `df_sales_by_id_name`.\n","    - This time, include the `product_name` information in addition to the `product_id` column.\n","- ‚úîÔ∏è Use the `groupby()` method.\n","- ‚úîÔ∏è `df_sales_by_id_name` should contain flat-level columns in the order shown below.\n","    - Printing `df_sales_by_id_name.columns.to_list()` should print out `['product_id', 'product_name', 'price']`.\n","\n","#### üß≠ Expected Output of `df_sales_by_id_name`\n","\n","|  | product_id | product_name | price |\n","|---|---|---|---|\n","| 0 | CB | Beer | 15 |\n","| 1 | SC | Sweetcorn | 21 |"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### BEGIN SOLUTION\n","\n","### END SOLUTION\n","\n","display(df_sales_by_id_name)"]},{"cell_type":"markdown","metadata":{},"source":["#### üß≠ Check Your Work\n","\n","- Once you're done, run the code cell below to test correctness.\n","- ‚úîÔ∏è If the code cell runs without an error, you're good to move on.\n","- ‚ùå If the code cell throws an error, go back and fix incorrect parts."]},{"cell_type":"code","execution_count":null,"metadata":{"nbgrader":{"grade":true,"grade_id":"challenge-07","locked":true,"points":"1","solution":false}},"outputs":[],"source":["df_merged_SOL = df_transactions_backup.merge(\n","    df_products_backup,\n","    on='product_id',\n","    how='left'\n",")\n","\n","df_sales_by_id_name_SOL = df_merged_SOL.groupby(['product_id', 'product_name'], as_index=False).agg({'price': 'sum'})\n","\n","pd.testing.assert_frame_equal(df_sales_by_id_name, df_sales_by_id_name_SOL)"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"nbformat":4,"nbformat_minor":4}